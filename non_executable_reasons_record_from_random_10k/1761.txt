3.6
An error occurred while executing the following cell:
------------------
import warnings
warnings.filterwarnings('ignore')
# coding: utf-8
# å†å¸°å‹ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®ä¾‹

# Kerasã§ä½¿ã†ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®èª­ã¿è¾¼ã¿
from keras.models import Sequential, Model
from keras.layers import Input, Embedding, LSTM, Dense
from keras.layers.wrappers import TimeDistributed

# IMDBãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®èª­ã¿è¾¼ã¿
from keras.datasets import imdb

# SVGã®è¡¨ç¤ºã«å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from IPython.display import SVG
from keras.utils.vis_utils import model_to_dot

# Windows ã®å ´åˆã¯ä»¥ä¸‹ã‚’è¿½åŠ 
#import os
#os.environ["PATH"] += os.pathsep + 'C:/Program Files (x86)/Graphviz2.38/bin/'

# Numpyãªã©ãƒ„ãƒ¼ãƒ«ã®èª­ã¿è¾¼ã¿
from keras.utils import to_categorical, np_utils
import numpy as np


# ãƒ‡ãƒ¼ã‚¿æ•°ã€ç‰¹å¾´æ•°ã€ãƒ™ã‚¯ãƒˆãƒ«ã®æ¬¡å…ƒæ•°ã€ã‚¹ãƒ†ãƒƒãƒ—æ•°ãªã©
train_reviews = 5000
valid_reviews = 100
max_features = 5000
embedding_size = 256
step_size = 5
batch_size = 32
index_from = 2
rnn_units = 128
epochs = 2
word_index_prev = {'<PAD>': 0, '<START>': 1, '<UNK>': 2}

# IMDBãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features, index_from=index_from)

# IMDBãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å˜èªæƒ…å ±ã‚’æŠ½å‡º
word_index = {word: (index + index_from) for word, index in imdb.get_word_index().items() if (index + index_from) < max_features}
word_index.update(word_index_prev)

# å˜èªæƒ…å ±ã‹ã‚‰è¾æ›¸ã‚’ä½œæˆ
index_word = {index: word for word, index in word_index.items()}

# æ–‡ç« ã‚’è¡¨ç¤ºã™ã‚‹é–¢æ•°
def print_sentence(sentence):
    for index in sentence:
        print(index_word[index], end=" ")
    print()

# æœ€åˆã®ï¼‘æ–‡ã‚’è¡¨ç¤º
print_sentence(x_train[0])

# å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã¨ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã«åˆ†ã‘ã‚‹
data_train = [t for s in x_train[:train_reviews] for t in s]
data_valid = [t for s in x_train[train_reviews:train_reviews+valid_reviews] for t in s]

# ãƒãƒƒãƒå‡¦ç†ã®ãŸã‚ã®é–¢æ•°å®šç¾©
def batch_generator(data, batch_size, step_size):
    seg_len = len(data) // batch_size
    steps_per_epoch = seg_len // step_size
    data_seg_list = np.asarray([data[int(i*seg_len):int((i+1)*seg_len)] for i in range(batch_size)])
    data_seg_list
    i = 0
    while True:
        x = data_seg_list[:, int(i*step_size):int((i+1)*step_size)]
        y = np.asarray([to_categorical(data_seg_list[j, int(i*step_size+1):int((i+1)*step_size+1)], max_features) for j in range(batch_size)])
        yield x, y
        i += 1
        if i >= steps_per_epoch:
            i = 0

# LSTMã‚’ä½¿ã£ã¦ãƒ¢ãƒ‡ãƒ«ã‚’è¨­è¨ˆ
w = Input(shape=(step_size,), name='Input')
x = Embedding(input_dim=max_features, output_dim=embedding_size, name='Embedding')(w)
y = LSTM(units=rnn_units, return_sequences=True, dropout=0.5, recurrent_dropout=0.5, name='LSTM')(x)
w_next = TimeDistributed(Dense(units=max_features, activation='softmax', name='Dense'), name='TimeDistributed')(y)

# ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆ
model = Model(inputs=[w], outputs=[w_next])

# ãƒ¢ãƒ‡ãƒ«ã®è¡¨ç¤º
SVG(model_to_dot(model, show_shapes=True).create(prog='dot', format='svg'))

# ãƒ¢ãƒ‡ãƒ«ã®ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«
model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])

# ãƒãƒƒãƒå‡¦ç†ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½œæˆ
gen_train = batch_generator(data_train, batch_size, step_size)
gen_valid = batch_generator(data_valid, batch_size, step_size)

# ã‚¹ãƒ†ãƒƒãƒ—æ•°ã‚’è¨ˆç®—
steps_per_epoch_train = len(data_train) / batch_size / step_size
steps_per_epoch_valid = len(data_valid) / batch_size / step_size

# ãƒãƒƒãƒå‡¦ç†ã”ã¨ã«ãƒ‡ãƒ¼ã‚¿ã‚’å­¦ç¿’
model.fit_generator(generator=gen_train, steps_per_epoch=steps_per_epoch_train, epochs=epochs,
                    validation_data=gen_valid, validation_steps=steps_per_epoch_valid)

# æ¬¡ã«ãã‚‹å˜èªã‚’é¸ã¶é–¢æ•°
def sample(preds, temperature=1.0):
    preds = np.log(preds) / temperature
    preds = np.exp(preds) / np.sum(np.exp(preds))
    choices = range(len(preds))
    return np.random.choice(choices, p=preds)

# ãƒ©ãƒ³ãƒ€ãƒ ã«æ–‡ç« ã‚’ç”Ÿæˆã™ã‚‹é–¢æ•°
def sample_sentences(num_sentences, sample_sent_len = 20):
    for x_test_i in x_test[:num_sentences]:
        x = np.zeros((1, step_size))
        sentence = x_test_i[:step_size]

        for i in range(sample_sent_len):
            for j, index in enumerate(sentence[-step_size:]):
                x[0, j] = index
            preds = model.predict(x)[0][-1]
            next_index = sample(preds)
            sentence.append(next_index)

        print_sentence(sentence)

# ãƒ©ãƒ³ãƒ€ãƒ ã«æ–‡ç« ã‚’æŠ½å‡º
sample_sentences(num_sentences=20, sample_sent_len=15)

# weightã‚’æ­£è¦åŒ–
norm_weights = np_utils.normalize(model.get_weights()[0])

# è¿‘ã„æ„å‘³ã®å˜èªã‚’è¡¨ç¤ºã™ã‚‹é–¢æ•°
def print_closest_words(word, nb_closest=10):
    index = word_index[word]
    distances = np.dot(norm_weights, norm_weights[index])
    c_indexes = np.argsort(np.squeeze(distances))[-nb_closest:][::-1]
    for c_index in c_indexes:
        print(index_word[c_index], distances[c_index])

# è¿‘ã„æ„å‘³ã®å˜èªã‚’è¡¨ç¤º
words = ["3",
         "two",
         "great",
         "money",
         "years",
         "look",
         "own",
         "us",
         "using",
        ]

for word in words:
    if word in word_index:
        print('====', word)
        print_closest_words(word)
------------------

[0;31m---------------------------------------------------------------------------[0m
[0;31mModuleNotFoundError[0m                       Traceback (most recent call last)
[0;32m<ipython-input-1-b0cbbbba10c9>[0m in [0;36m<module>[0;34m[0m
[1;32m      5[0m [0;34m[0m[0m
[1;32m      6[0m [0;31m# Kerasã§ä½¿ã†ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®èª­ã¿è¾¼ã¿[0m[0;34m[0m[0;34m[0m[0;34m[0m[0m
[0;32m----> 7[0;31m [0;32mfrom[0m [0mkeras[0m[0;34m.[0m[0mmodels[0m [0;32mimport[0m [0mSequential[0m[0;34m,[0m [0mModel[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m      8[0m [0;32mfrom[0m [0mkeras[0m[0;34m.[0m[0mlayers[0m [0;32mimport[0m [0mInput[0m[0;34m,[0m [0mEmbedding[0m[0;34m,[0m [0mLSTM[0m[0;34m,[0m [0mDense[0m[0;34m[0m[0;34m[0m[0m
[1;32m      9[0m [0;32mfrom[0m [0mkeras[0m[0;34m.[0m[0mlayers[0m[0;34m.[0m[0mwrappers[0m [0;32mimport[0m [0mTimeDistributed[0m[0;34m[0m[0;34m[0m[0m

[0;31mModuleNotFoundError[0m: No module named 'keras'
ModuleNotFoundError: No module named 'keras'

Executability                            : False
