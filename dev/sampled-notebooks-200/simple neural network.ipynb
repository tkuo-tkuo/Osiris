{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nonlin(x, deriv=False):  # Note: there is a typo on this line in the video\n",
    "    if(deriv==True):\n",
    "        return (x*(1-x))\n",
    "    \n",
    "    return 1/(1+np.exp(-x))  # this will map any value between 0 and 1, turns numbers into probabilties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.array([[0,0,1],\n",
    "              [0,1,1],\n",
    "              [1,0,1],\n",
    "              [1,1,1]]) # 4x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1],\n",
       "       [0, 1, 1],\n",
       "       [1, 0, 1],\n",
       "       [1, 1, 1]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X # input data, 4 training examples (rows) with three nerons (columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = np.array([[0],\n",
    "             [1],\n",
    "             [1],\n",
    "             [0]]) # output data, 4x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# synapses, connections between each nerion in one layer to every neuron in the next layer\n",
    "# note X has 3 cols 2 are inputs the 3rd is a bias term (cosntant term)\n",
    "#syn0 below is are the weights from input layer to hidden layer, a 3x4 matrix becasue there are (2+1)=3 inputs and 4 nodes\n",
    "#sun1 are the weights between the hidden layer and the output layer, 4x1 , 4 nodes in hidden layer produce the \n",
    "#inputs and one is for the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#synapses, layers in our network mean we need 2 matricies; this is the nerual network\n",
    "syn0 = 2*np.random.random((3,4)) - 1  # 3x4 matrix of weights ((2 inputs + 1 bias) x 4 nodes in the hidden layer)\n",
    "syn1 = 2*np.random.random((4,1)) - 1  # 4x1 matrix of weights. (4 nodes x 1 output) - no bias term in the hidden layer\n",
    "# starting with random weights is best practice for optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.16595599,  0.44064899, -0.99977125, -0.39533485],\n",
       "       [-0.70648822, -0.81532281, -0.62747958, -0.30887855],\n",
       "       [-0.20646505,  0.07763347, -0.16161097,  0.370439  ]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syn0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.5910955 ],\n",
       "       [ 0.75623487],\n",
       "       [-0.94522481],\n",
       "       [ 0.34093502]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syn1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# note each synapse has a random weight asssiged to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create our first layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 0.00318350238587\n",
      "Error: 0.00293230634228\n",
      "Error: 0.00273150641821\n",
      "Error: 0.00256631724004\n",
      "Error: 0.00242737608676\n",
      "Error: 0.00230843116063\n",
      "Error: 0.00220512937522\n",
      "Error: 0.0021143350549\n",
      "Error: 0.00203372513685\n",
      "Error: 0.0019615374333\n",
      "Output after training\n",
      "[[ 0.00155944]\n",
      " [ 0.99806849]\n",
      " [ 0.99820156]\n",
      " [ 0.00229627]]\n"
     ]
    }
   ],
   "source": [
    "# training steo\n",
    "for j in range(100000):\n",
    "    l0 = X\n",
    "    l1 = nonlin(np.dot(l0,syn0)) # note l0 is X which is 4x3, syn0 is 3x4 so output from np.dot is 4x4\n",
    "    l2 = nonlin(np.dot(l1,syn1)) # then l1 is 4x4, syn1 4x1 so output from np.dot is 4x1\n",
    "    \n",
    "    l2_error = y - l2\n",
    "    if(j % 10000) == 0:\n",
    "        \n",
    "        print(\"Error: \" + str(np.mean(np.abs(l2_error))))\n",
    "        \n",
    "    l2_delta = l2_error*nonlin(l2, deriv=True) # 4x1 matrix l2 matrix updated probabilites\n",
    "    \n",
    "    l1_error = l2_delta.dot(syn1.T) # take the avove line result and dot product transpose of syn1, 4x1.1x4 = 4x4 = l1_error\n",
    "    \n",
    "    l1_delta = l1_error * nonlin(l1,deriv=True) # l1_delta is l1_error 4x4. probabilities l1 4x4 = 4x4.4x4 = 4x4\n",
    "    \n",
    "    #update weights (by the deltas) (no learning rate term)\n",
    "    syn1 += l1.T.dot(l2_delta)\n",
    "    syn0 += l0.T.dot(l1_delta)\n",
    "        \n",
    "print('Output after training')\n",
    "print(l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n"
     ]
    }
   ],
   "source": [
    "print('hello world')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
